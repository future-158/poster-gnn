version: "3.3"
services:
  db:
    restart: always
    image: postgres:11
    container_name: mlflow_db
    expose:
      - "${PG_PORT}"
    networks:
      - backend
    environment:
      - POSTGRES_USER=${PG_USER}
      - POSTGRES_PASSWORD=${PG_PASSWORD}
      - POSTGRES_DATABASE=${PG_DATABASE}
    volumes:
      - db_data:/var/lib/postgresql/data/

  s3:
    image: minio/minio:RELEASE.2020-12-18T03-27-42Z
    container_name: mlflow_s3
    volumes:
      - minio_data:/data
    ports:
      - "${MINIO_PORT}:9000"
    networks:
      - frontend
      - backend
    environment:
      - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY}
      - MINIO_SECRET_KEY=${MINIO_SECRET_ACCESS_KEY}
    command: server /data
    healthcheck:
      test:
        [
          "CMD",
          "curl",
          "-f",
          "http://localhost:9000/minio/health/live"
        ]
      interval: 30s
      timeout: 20s
      retries: 3

  create_buckets:
    image: minio/mc:RELEASE.2019-07-17T22-13-42Z
    container_name: mlflow_create_buckets
    depends_on:
      - s3
    networks:
      - backend
    entrypoint: >
      /bin/sh -c ' sleep 5; /usr/bin/mc config host add s3 http://s3:9000 ${MINIO_ACCESS_KEY} ${MINIO_SECRET_ACCESS_KEY} --api S3v4; [[ ! -z "`/usr/bin/mc ls s3 | grep challenge`" ]] || /usr/bin/mc mb s3/${MLFLOW_BUCKET_NAME}; /usr/bin/mc policy download s3/${MLFLOW_BUCKET_NAME}; [[ ! -z "`/usr/bin/mc ls s3 | grep challenge`" ]] || /usr/bin/mc mb s3/${DATA_REPO_BUCKET_NAME}; /usr/bin/mc policy download s3/${DATA_REPO_BUCKET_NAME}; exit 0; '      

  tracking_server:
    restart: always
    build:
      # "context" and "dockerfile" fields have to be under "build"
      context: .
      dockerfile: mlflow.Dockerfile
    container_name: mlflow_tracking_server
    # image: localhost:5005/poster/mlflow
    ports:
      - "${MLFLOW_PORT}:5000"
    networks:
      - frontend
      - backend
    environment:
      - AWS_ACCESS_KEY_ID=${MINIO_ACCESS_KEY}
      - AWS_SECRET_ACCESS_KEY=${MINIO_SECRET_ACCESS_KEY}
      - MLFLOW_S3_ENDPOINT_URL=http://s3:9000
    command: >
      mlflow server  --backend-store-uri postgresql://${PG_USER}:${PG_PASSWORD}@db:${PG_PORT}/${PG_DATABASE} --host 0.0.0.0 --default-artifact-root s3://mlflow/      

  codeserver:
    restart: always
    image: localhost:5005/poster/pyg
    container_name: mlflow_codeserver
    # working_dir: /workspace
    # user: root
    ports:
      - "${JUPYTER_PORT}:8888"
    volumes:
      - ${ROOT}/data:/data
      - ${ROOT}/dataset:/dataset
      - ${WD}:/workspace
    networks:
      - frontend
      - backend
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ '0', '3', '7' ]
              capabilities: [ gpu ]

  # ray:
  #   restart: always
  #   image: rayproject/ray-ml:1.3.0-py38-gpu
  #   container_name: mlflow_ray
  #   # image: localhost:5005/poster/mlflow
  #   ports:
  #     - "${RAY_DASHBOARD_PORT}:8265"
  #   networks:
  #     - frontend
  #     - backend
  #   command: >
  #     sh -c "ray start --num-gpus=1 --num-cpus=10  --head  --port 6379  --object-manager-port=8076  --include-dashboard=true  --dashboard-host=0.0.0.0  --dashboard-port=8265 && sleep 9999999"
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             device_ids: [ '0' ]
  #             capabilities: [ gpu ]

  # ray_worker:
  #   restart: always
  #   image: rayproject/ray-ml:1.3.0-py38-gpu
  #   container_name: mlflow_ray_worker
  #   # image: localhost:5005/poster/mlflow
  #   ports:
  #     - "${RAY_DASHBOARD_PORT}:8265"
  #   networks:
  #     - frontend
  #     - backend
  #   command: >
  #     sh -c "sleep 30 && ray start --num-gpus=1 --num-cpus=30  --address mlflow_ray:6379 && sleep 9999999"
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             device_ids: [ '7' ]
  #             capabilities: [ gpu ]

volumes:
  db_data:
  minio_data:

networks:
  frontend:
    driver: bridge
  backend:
    driver: bridge
